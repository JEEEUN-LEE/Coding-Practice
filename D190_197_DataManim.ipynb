{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd6312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>channelId</th>\n",
       "      <th>trending_date2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[신병] 물자창고</td>\n",
       "      <td>장삐쭈</td>\n",
       "      <td>23</td>\n",
       "      <td>1893473</td>\n",
       "      <td>38249</td>\n",
       "      <td>730</td>\n",
       "      <td>8595</td>\n",
       "      <td>UChbE5OZQ6dRHECsX0tEPEZQ</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV</td>\n",
       "      <td>RAIN's Official Channel</td>\n",
       "      <td>10</td>\n",
       "      <td>2600864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20129</td>\n",
       "      <td>UCxXgIeE5hxWxHG6dz9Scg2w</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.</td>\n",
       "      <td>서울시 · Seoul</td>\n",
       "      <td>29</td>\n",
       "      <td>347049</td>\n",
       "      <td>3564</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>UCZUPZW5idAxYp-Asj__lVAA</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고기남자의 칠면조 파티</td>\n",
       "      <td>고기남자 MeatMan</td>\n",
       "      <td>26</td>\n",
       "      <td>528458</td>\n",
       "      <td>15372</td>\n",
       "      <td>280</td>\n",
       "      <td>3470</td>\n",
       "      <td>UCT3CumbFIJiW33uq0UI3zlg</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...</td>\n",
       "      <td>스브스밥집</td>\n",
       "      <td>24</td>\n",
       "      <td>494904</td>\n",
       "      <td>3918</td>\n",
       "      <td>111</td>\n",
       "      <td>3142</td>\n",
       "      <td>UCdWgRSfttvDucq4ApcCg5Mw</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             channelTitle  \\\n",
       "0                                          [신병] 물자창고                      장삐쭈   \n",
       "1   RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV  RAIN's Official Channel   \n",
       "2       2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.              서울시 · Seoul   \n",
       "3                                       고기남자의 칠면조 파티             고기남자 MeatMan   \n",
       "4  골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...                    스브스밥집   \n",
       "\n",
       "   categoryId  view_count  likes  dislikes  comment_count  \\\n",
       "0          23     1893473  38249       730           8595   \n",
       "1          10     2600864      0         0          20129   \n",
       "2          29      347049   3564       120            178   \n",
       "3          26      528458  15372       280           3470   \n",
       "4          24      494904   3918       111           3142   \n",
       "\n",
       "                  channelId trending_date2  \n",
       "0  UChbE5OZQ6dRHECsX0tEPEZQ     2021-01-01  \n",
       "1  UCxXgIeE5hxWxHG6dz9Scg2w     2021-01-01  \n",
       "2  UCZUPZW5idAxYp-Asj__lVAA     2021-01-01  \n",
       "3  UCT3CumbFIJiW33uq0UI3zlg     2021-01-01  \n",
       "4  UCdWgRSfttvDucq4ApcCg5Mw     2021-01-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터마님 1유형 01\n",
    "# https://www.datamanim.com/dataset/03_dataq/typeone.html\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/youtube.csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c79500eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'channelTitle', 'categoryId', 'view_count', 'likes',\n",
       "       'dislikes', 'comment_count', 'channelId', 'trending_date2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2697",
   "metadata": {},
   "source": [
    "## 1유형-01 [Try 코드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd794c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기 동영상 제작횟수가 많은 채널 상위 10개명을 출력하라 (날짜기준, 중복포함)\n",
    "\n",
    "# 1. 날짜 기준 정렬\n",
    "df.sort_values('trending_date2', ascending = False, inplace = True)\n",
    "# 2. 채널명 개수 세서, 상위 10개 추출\n",
    "top10_channel = df[df['channelTitle'].value_counts().head(10)]\n",
    "# 3. 채널명만 리스트로 출력\n",
    "top10_channel_list = top10_channel['channelTitle'].unique().tolist()\n",
    "top10_channel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85c2bc",
   "metadata": {},
   "source": [
    "<틀린 부분>\n",
    "- channel_ID 기준.\n",
    "- value_counts().head()는 Series로 출력되어 바로 df[] 필터를 사용할 수 없음\n",
    "채널명은 index, 카운트값은 value 로 출력됨.\n",
    "채널명인 index로만 필터해야함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7bef8",
   "metadata": {},
   "source": [
    "## 1유형-01 [Answer 코드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2650c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['장삐쭈',\n",
       " '파뿌리',\n",
       " '짤툰',\n",
       " '총몇명',\n",
       " '엠뚜루마뚜루 : MBC 공식 종합 채널',\n",
       " '런닝맨 - 스브스 공식 채널',\n",
       " 'SPOTV',\n",
       " '채널 십오야',\n",
       " '이과장',\n",
       " 'BANGTANTV']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 날짜 기준으로 정렬\n",
    "df.sort_values('trending_date2', ascending = True, inplace = True)\n",
    "# 2. 채널 id 기준으로 개수 세서, 상위 10개 뽑기, 해당되는 행만 필터링\n",
    "channel_counts = df['channelId'].value_counts().head(10)\n",
    "top10_channel = df[df['channelId'].isin(channel_counts.index)]\n",
    "# 3. 채널명만 중복 없이 리스트로 출력\n",
    "top10_channel['channelTitle'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f575479e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['장삐쭈',\n",
       " '런닝맨 - 스브스 공식 채널',\n",
       " '짤툰',\n",
       " '총몇명',\n",
       " '파뿌리',\n",
       " '엠뚜루마뚜루 : MBC 공식 종합 채널',\n",
       " 'SPOTV',\n",
       " '채널 십오야',\n",
       " '이과장',\n",
       " 'BANGTANTV']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('trending_date2', ascending = True, inplace = True)\n",
    "\n",
    "df_topID = df['channelId'].value_counts().head(10).index\n",
    "df_toptitle = df[df['channelId'].isin(df_topID)]\n",
    "df_toptitle['channelTitle'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134869af",
   "metadata": {},
   "source": [
    "## 1유형-02 [Try 코드] [정답!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db77e1",
   "metadata": {},
   "source": [
    "채널명을 바꾼 케이스가 있는지 확인하고 싶다. channelId의 경우 고유값이므로 이를 통해 채널명을 한번이라도 바꾼 채널의 갯수를 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a225d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. channelId 기준 그룹화해서 channelTitle 유니크값이 2개 이상인 것만 필터링\n",
    "df_grouped = df.groupby('channelId')['channelTitle'].nunique()\n",
    "df_grouped = df_grouped[df_grouped > 1]\n",
    "len(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7dd3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# 모범 답안\n",
    "change = df[['channelTitle','channelId']].drop_duplicates().channelId.value_counts()\n",
    "target = change[change>1]\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920fc4f",
   "metadata": {},
   "source": [
    "## 1유형-03 [Try 코드]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811eeba2",
   "metadata": {},
   "source": [
    "일요일에 인기있었던 영상들중 가장많은 영상 종류(categoryId)는 무엇인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "951ce3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trending_date2에서 무슨 요일인지로 변경해서 변수 생성. '일요일'인 행만 필터링\n",
    " # 날짜형식 변경\n",
    "df['trending_date2'] = pd.to_datetime(df['trending_date2'])\n",
    " # 요일 추출\n",
    "df['dayname'] = df['trending_date2'].dt.day_name()\n",
    "df.head()\n",
    " # '일요일'인 행만 필터링\n",
    "df_Sun = df[df['dayname'] =='Sunday']\n",
    "\n",
    "# 그 중 likes가 가장 높은 행의 categoryId를 출력\n",
    "df_Sun_like = df_Sun.sort_values('likes', ascending = False).head(1)\n",
    "df_Sun_like['categoryId'].values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eeb0ae",
   "metadata": {},
   "source": [
    "- 문제 이해 잘못.. 가장 좋아요 많은게 아니라 가장 많은 categoryID를 추출하는거임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00322ad7",
   "metadata": {},
   "source": [
    "## 1유형-03 [정답 코드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7755674b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trending_date2'] = pd.to_datetime(df['trending_date2'])\n",
    "df['dayname'] = df['trending_date2'].dt.day_name()\n",
    "\n",
    "df_Sun = df[df['dayname'] == 'Sunday']\n",
    "answer = df_Sun['categoryId'].value_counts().head(1).index[0]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed289fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -04. 일요일에 인기있었던 영상들중 가장많은 영상 종류(categoryId)는 무엇인가?\n",
    "df['trending_date2'] = pd.to_datetime(df['trending_date2'])\n",
    "\n",
    "df['day'] = df['trending_date2'].dt.day_name()\n",
    "df_Sun = df[df['day'] == 'Sunday']\n",
    "df_Sun['categoryId'].value_counts().head(1).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b29e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jee36\\AppData\\Local\\Temp\\ipykernel_36696\\3576755677.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['trending_date2'] = pd.to_datetime(df['trending_date2'])\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unable to parse datetime string: Friday, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -05. 각 요일별 인기 영상들의 categoryId는 각각 몇개 씩인지 하나의 데이터 프레임으로 표현하라\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrending_date2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrending_date2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrending_date2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrending_date2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday_name()\n\u001b[0;32m      4\u001b[0m group \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrending_date2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategoryId\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\my-project\\myenv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\my-project\\myenv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\my-project\\myenv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\my-project\\myenv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:678\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unable to parse datetime string: Friday, at position 0"
     ]
    }
   ],
   "source": [
    "# -05. 각 요일별 인기 영상들의 categoryId는 각각 몇개 씩인지 하나의 데이터 프레임으로 표현하라\n",
    "df['trending_date2'] = pd.to_datetime(df['trending_date2'])\n",
    "df['trending_date2'] = df['trending_date2'].dt.day_name()\n",
    "group = df.groupby(['trending_date2','categoryId']).size().reset_index(name = 'size')\n",
    "group.pivot(index = 'categoryId', columns = 'trending_date2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64ce797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60분 동안 댓글이 달리지 않으면, 영상이 삭제됩니다. (챌린지)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6. 댓글의 수로(comment_count) 영상 반응에 대한 판단을 할 수 있다.\n",
    "# viewcount대비 댓글수가 가장 높은 영상을 확인하라 (view_count값이 0인 경우는 제외한다)\n",
    "\n",
    "# 1. view_count 값이 0이 아닌 행만 필터링\n",
    "df2 = df.copy()\n",
    "df2 = df2[df2['view_count']!= 0]\n",
    "# 2. comment_count / view_count 구해서 변수 생성\n",
    "df2[['comment_count', 'view_count']] = df2[['comment_count', 'view_count']].astype(int)\n",
    "df2['ratio'] = df2['comment_count'] / df2['view_count']\n",
    "answer = df2.sort_values(by = 'ratio', ascending = False).head(1).title\n",
    "answer.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b8a936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Join the BTS #PermissiontoDance Challenge only on YouTube #Shorts'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 7. 댓글의 수로 (comment_count) 영상 반응에 대한 판단을 할 수 있다.\n",
    "# viewcount대비 댓글수가 가장 낮은 영상을 확인하라 (view_counts, ratio값이 0인경우는 제외한다.)\n",
    "\n",
    "df3 = df.copy()\n",
    "df3['ratio'] = df3['comment_count'] / df3['view_count']\n",
    "df3 = df3[df3['ratio'] != 0]\n",
    "answer = df3.sort_values(by = 'ratio', ascending = True).head(1).title\n",
    "answer.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701efe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8\n",
    "\n",
    "# like 대비 dislike의 수가 가장 적은 영상은 무엇인가? (like, dislike 값이 0인경우는 제외한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50038888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = df2[(df2['likes'] !=0) & (df2['dislikes'] !=0)]\n",
    "df2['ratio'] = df2['dislikes'] / df2['likes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f67cd",
   "metadata": {},
   "source": [
    "⭐ 오류 체크\n",
    "\n",
    "괄호 ( )를 안할 경우 다음과 같은 오류가 남. 왜냐, '&'가 '!=' 보다 우선순위가 낮아서 다른 순서로 계산됨.\n",
    "\n",
    "ValueError: The truth value of a Series is ambiguous.\n",
    "'&' 대신 'and'를 사용할 수 없음. 왜냐, '&' 연산자는 각 조건의 결과가 Series일 때 원소 단위로 AND 연산을 해주고, 'and, or' 등은 단일값일 때 사용할 수 있음\n",
    "\n",
    "\n",
    "df2['ratio'] = df2['ratio'].sort_values() 이렇게 하면 df['ratio']만 정렬되므로, df2 전체가 정렬될 수 있도록 df2 = df2.sort_values('ratio') 이걸로 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sort_values(by = 'ratio', ascending = True)\n",
    "answer = df2['title'].head(1)\n",
    "answer.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16743f72",
   "metadata": {},
   "source": [
    ":Question 9\n",
    "\n",
    "가장많은 트렌드 영상을 제작한 채널의 이름은 무엇인가? (날짜기준, 중복포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channelTitle 별 그룹화하고, trending date2 개수 카운트\n",
    "group = df2.groupby(by = 'channelTitle', as_index = False)['trending_date2'].nunique().sort_values(by ='trending_date2', ascending = False)\n",
    "group['channelTitle'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f39a23",
   "metadata": {},
   "source": [
    "Question 10\n",
    "\n",
    "20회(20일)이상 인기동영상 리스트에 포함된 동영상의 숫자는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1258b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title 기준 그룹화하고, trending date nuique 값이 20 이상인 필터링, len() 개수 세기\n",
    "group = df2.groupby(by = ['title', 'channelId'], as_index = False)['trending_date2'].nunique()\n",
    "len(group['trending_date2'] >= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b82d0",
   "metadata": {},
   "source": [
    "⭐ 오류 체크\n",
    "\n",
    "여러개 항목 기준으로 그룹화 하려면 by = ['항목1', '항목2'] []로 활용\n",
    "중복을 포함하지 않는 경우를 구할려면 nunique()이고, 중복 포함하여 20개 이상인 것만 보려면 value_counts\n",
    "그리고 len()만 쓸 경우 전체 데이터 숫자를 세게됨. 설정한 조건이 True인 것만 세려면 count한거의 sum()을 사용해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548efaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "df2 = df.copy()\n",
    "\n",
    "# title,channelId 기준 그룹화하고, trending date nuique 값이 20 이상인 필터링, len() 개수 세기\n",
    "answer = (df2[['title','channelId']].value_counts() >=20).sum()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e76a22",
   "metadata": {},
   "source": [
    "## 유튜브 공범컨텐츠 동영상 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736a9d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelid</th>\n",
       "      <th>subcnt</th>\n",
       "      <th>viewcnt</th>\n",
       "      <th>videocnt</th>\n",
       "      <th>ct</th>\n",
       "      <th>channelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>410238653</td>\n",
       "      <td>736</td>\n",
       "      <td>2021-09-30 03:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>736</td>\n",
       "      <td>2021-09-30 09:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>735</td>\n",
       "      <td>2021-09-30 15:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>737</td>\n",
       "      <td>2021-09-30 21:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1320000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>737</td>\n",
       "      <td>2021-10-01 03:01:04</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelid   subcnt    viewcnt  videocnt  \\\n",
       "0  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  410238653       736   \n",
       "1  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       736   \n",
       "2  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       735   \n",
       "3  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       737   \n",
       "4  UCkQCwnkQfgSuPTTnw_Y7v7w  1320000  412531322       737   \n",
       "\n",
       "                    ct channelname  \n",
       "0  2021-09-30 03:01:03         꽈뚜룹  \n",
       "1  2021-09-30 09:01:03         꽈뚜룹  \n",
       "2  2021-09-30 15:01:03         꽈뚜룹  \n",
       "3  2021-09-30 21:01:03         꽈뚜룹  \n",
       "4  2021-10-01 03:01:04         꽈뚜룹  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videopk</th>\n",
       "      <th>viewcnt</th>\n",
       "      <th>likecnt</th>\n",
       "      <th>dislikecnt</th>\n",
       "      <th>favoritecnt</th>\n",
       "      <th>cmcnt</th>\n",
       "      <th>ct</th>\n",
       "      <th>videoname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1667010</td>\n",
       "      <td>30474</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>6587</td>\n",
       "      <td>2021-10-10 15:20:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1669089</td>\n",
       "      <td>30495</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "      <td>6589</td>\n",
       "      <td>2021-10-10 15:30:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1674759</td>\n",
       "      <td>30522</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>6596</td>\n",
       "      <td>2021-10-10 15:40:02</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1677026</td>\n",
       "      <td>30555</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>6604</td>\n",
       "      <td>2021-10-10 15:50:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1681824</td>\n",
       "      <td>30585</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>6600</td>\n",
       "      <td>2021-10-10 16:00:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videopk  viewcnt  likecnt  dislikecnt  favoritecnt  cmcnt  \\\n",
       "0  c5JQp6xafqc  1667010    30474         706            0   6587   \n",
       "1  c5JQp6xafqc  1669089    30495         707            0   6589   \n",
       "2  c5JQp6xafqc  1674759    30522         711            0   6596   \n",
       "3  c5JQp6xafqc  1677026    30555         712            0   6604   \n",
       "4  c5JQp6xafqc  1681824    30585         713            0   6600   \n",
       "\n",
       "                    ct videoname  \n",
       "0  2021-10-10 15:20:03    공범 EP1  \n",
       "1  2021-10-10 15:30:03    공범 EP1  \n",
       "2  2021-10-10 15:40:02    공범 EP1  \n",
       "3  2021-10-10 15:50:03    공범 EP1  \n",
       "4  2021-10-10 16:00:03    공범 EP1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "channel =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/channelInfo.csv')\n",
    "video =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/videoInfo.csv')\n",
    "display(channel.head())\n",
    "display(video.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6589699",
   "metadata": {},
   "source": [
    "Question 11\n",
    "\n",
    "각 데이터의 ‘ct’컬럼을 시간으로 인식할수 있게 datatype을 변경하고 video 데이터의 videoname의 각 value 마다 몇개의 데이터씩 가지고 있는지 확인하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbef4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "videoname\n",
       "공범 EP1    3492\n",
       "공범 EP2    3204\n",
       "공범 EP3    2568\n",
       "공범 EP4    2280\n",
       "공범 EP5    1562\n",
       "공범 EP6    1274\n",
       "공범 EP7     555\n",
       "공범 EP8     266\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel['ct'] = pd.to_datetime(channel['ct'])\n",
    "video['ct'] = pd.to_datetime(video['ct'])\n",
    "\n",
    "answer = video['videoname'].value_counts()\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f43d67",
   "metadata": {},
   "source": [
    "Question 12\n",
    "\n",
    "수집된 각 video의 가장 최신화 된 날짜의 viewcount값을 출력하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7264966b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewcnt</th>\n",
       "      <th>ct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>videoname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>공범 EP1</th>\n",
       "      <td>3180532</td>\n",
       "      <td>2021-11-01 15:30:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP2</th>\n",
       "      <td>2199328</td>\n",
       "      <td>2021-11-01 15:30:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP3</th>\n",
       "      <td>1671294</td>\n",
       "      <td>2021-11-01 15:30:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP4</th>\n",
       "      <td>1818493</td>\n",
       "      <td>2021-11-01 15:30:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP5</th>\n",
       "      <td>1503435</td>\n",
       "      <td>2021-11-01 15:30:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP6</th>\n",
       "      <td>1750222</td>\n",
       "      <td>2021-11-01 15:30:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP7</th>\n",
       "      <td>1630200</td>\n",
       "      <td>2021-11-01 15:30:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP8</th>\n",
       "      <td>1289088</td>\n",
       "      <td>2021-11-01 15:30:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           viewcnt                  ct\n",
       "videoname                             \n",
       "공범 EP1     3180532 2021-11-01 15:30:03\n",
       "공범 EP2     2199328 2021-11-01 15:30:03\n",
       "공범 EP3     1671294 2021-11-01 15:30:03\n",
       "공범 EP4     1818493 2021-11-01 15:30:03\n",
       "공범 EP5     1503435 2021-11-01 15:30:04\n",
       "공범 EP6     1750222 2021-11-01 15:30:04\n",
       "공범 EP7     1630200 2021-11-01 15:30:05\n",
       "공범 EP8     1289088 2021-11-01 15:30:05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정렬\n",
    "sorting = video.sort_values(['videoname', 'ct'], ascending = False)\n",
    "# video 별로 첫번째 행의 viewcnt 값 출력\n",
    "answer = sorting.groupby('videoname').first()[['viewcnt', 'ct']]\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cb2e1",
   "metadata": {},
   "source": [
    "Question 13\n",
    "\n",
    "Channel 데이터중 2021-10-03일 이후 각 채널의 처음 기록 됐던 구독자 수(subcnt)를 출력하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd984fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcnt</th>\n",
       "      <th>ct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channelname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Balming Tiger</th>\n",
       "      <td>54300</td>\n",
       "      <td>2021-10-03 03:01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>곽토리 kwak tori</th>\n",
       "      <td>471000</td>\n",
       "      <td>2021-10-03 03:01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>김농밀의 농밀한 삶</th>\n",
       "      <td>7520</td>\n",
       "      <td>2021-10-03 03:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>꽈뚜룹</th>\n",
       "      <td>1330000</td>\n",
       "      <td>2021-10-03 03:01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>논리왕 전기</th>\n",
       "      <td>922000</td>\n",
       "      <td>2021-10-03 03:01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>릴펄 Lilpearl</th>\n",
       "      <td>10100</td>\n",
       "      <td>2021-10-03 03:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>야전삽짱재</th>\n",
       "      <td>257000</td>\n",
       "      <td>2021-10-03 03:01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>와글와글 WagleWagle</th>\n",
       "      <td>55000</td>\n",
       "      <td>2021-10-03 03:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>조나단</th>\n",
       "      <td>215000</td>\n",
       "      <td>2021-10-03 03:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>츄정ChuJeong</th>\n",
       "      <td>322000</td>\n",
       "      <td>2021-10-03 03:01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>형사!탐정되다</th>\n",
       "      <td>14900</td>\n",
       "      <td>2021-10-03 03:01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  subcnt                  ct\n",
       "channelname                                 \n",
       "Balming Tiger      54300 2021-10-03 03:01:04\n",
       "곽토리 kwak tori     471000 2021-10-03 03:01:04\n",
       "김농밀의 농밀한 삶          7520 2021-10-03 03:01:03\n",
       "꽈뚜룹              1330000 2021-10-03 03:01:04\n",
       "논리왕 전기            922000 2021-10-03 03:01:02\n",
       "릴펄 Lilpearl        10100 2021-10-03 03:01:03\n",
       "야전삽짱재             257000 2021-10-03 03:01:02\n",
       "와글와글 WagleWagle    55000 2021-10-03 03:01:03\n",
       "조나단               215000 2021-10-03 03:01:03\n",
       "츄정ChuJeong        322000 2021-10-03 03:01:02\n",
       "형사!탐정되다            14900 2021-10-03 03:01:03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_filtered= channel.loc[channel['ct'] >= '2021-10-03']\n",
    "channel_filtered.groupby('channelname').first()[['subcnt', 'ct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919281b",
   "metadata": {},
   "source": [
    "Question 14\n",
    "\n",
    "각채널의 2021-10-03 03:00:00 ~ 2021-11-01 15:00:00 까지 구독자수 (subcnt) 의 증가량을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae84e711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channelname\n",
       "Balming Tiger       2500\n",
       "곽토리 kwak tori      -2000\n",
       "김농밀의 농밀한 삶          1540\n",
       "꽈뚜룹                70000\n",
       "논리왕 전기            -11000\n",
       "릴펄 Lilpearl        11000\n",
       "야전삽짱재              11000\n",
       "와글와글 WagleWagle        0\n",
       "조나단                12000\n",
       "츄정ChuJeong          1000\n",
       "형사!탐정되다            10300\n",
       "Name: subcnt, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_filtered = channel.loc[(channel['ct'] >= '2021-10-03 03:00:00') & (channel['ct'] <= '2021-11-01 15:00:00 ')]\n",
    "\n",
    "# 채널별 끝행 구독자수- 처음행 구독자수, '증가량' 변수 생성\n",
    "channel_filtered.sort_values(['channelname', 'ct'])\n",
    "answer = channel_filtered.groupby('channelname').last()['subcnt'] - channel_filtered.groupby('channelname').first()['subcnt']\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097cd6a",
   "metadata": {},
   "source": [
    "Question 15\n",
    "\n",
    "각 비디오는 10분 간격으로 구독자수, 좋아요, 싫어요수, 댓글수가 수집된것으로 알려졌다. 공범 EP1의 비디오정보 데이터중 수집간격이 5분 이하, 20분이상인 데이터 구간( 해당 시점 전,후) 의 시각을 모두 출력하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f242a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jee36\\AppData\\Local\\Temp\\ipykernel_4028\\3224741422.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ep1['ct'] = pd.to_datetime(ep1['ct'])\n",
      "C:\\Users\\jee36\\AppData\\Local\\Temp\\ipykernel_4028\\3224741422.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ep1.sort_values('ct', inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#  공범 EP1의 비디오 필터링, ct로 오름차순 정렬\n",
    "import pandas as pd\n",
    "ep1 = video[video['videoname'] == ' 공범 EP1']\n",
    "ep1['ct'] = pd.to_datetime(ep1['ct'])\n",
    "ep1.sort_values('ct', inplace = True)\n",
    "\n",
    "# 현재 행과 그 다음 행의 ct 간격이 차이가 5분 이하 또는 20분 이상인 행 필터링(해당 시점 전 후 모두 출력)\n",
    "\n",
    "## 모르겠음..><"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7f381",
   "metadata": {},
   "source": [
    "Question 16\n",
    "\n",
    "각 에피소드의 시작날짜(년-월-일)를 에피소드 이름과 묶어 데이터 프레임으로 만들고 출력하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jee36\\AppData\\Local\\Temp\\ipykernel_4028\\1562843009.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered['ct'] = pd.to_datetime(filtered['ct'])\n",
      "C:\\Users\\jee36\\AppData\\Local\\Temp\\ipykernel_4028\\1562843009.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered['ct'] = filtered['ct'].dt.date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "videoname\n",
       "공범 EP1    2021-10-07\n",
       "공범 EP2    2021-10-09\n",
       "공범 EP3    2021-10-14\n",
       "공범 EP4    2021-10-16\n",
       "공범 EP5    2021-10-21\n",
       "공범 EP6    2021-10-23\n",
       "공범 EP7    2021-10-28\n",
       "공범 EP8    2021-10-30\n",
       "Name: ct, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "filtered = video[['videoname', 'ct']]\n",
    "filtered['ct'] = pd.to_datetime(filtered['ct'])\n",
    "filtered['ct'] = filtered['ct'].dt.date\n",
    "filtered= filtered.sort_values('ct')\n",
    "answer = filtered.groupby('videoname').first()['ct'] \n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b23e8",
   "metadata": {},
   "source": [
    "⭐ 오류 체크\n",
    "\n",
    "- groupby('그룹화할 항목').first() 하고 'ct' 기준으로 오름차순 해서 오답됨.\n",
    "- 'ct' 기준으로 오름차순 정렬 먼저 한 후, 'videoname' 기준 그룹화해서 first()로 첫 행들만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. 시간 간의 차이 계산(분), 필터링\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part1/ch3/delivery_time.csv\")\n",
    "print(df.head(2))\n",
    "\n",
    "print(df.info())\n",
    "# 기존 데이터 행 개수 확인\n",
    "print(len(df))\n",
    "\n",
    "# (1) 예상 도착 시간보다 늦게 도착한 건수를 구하시오.\n",
    "df['실제도착시간'] = pd.to_datetime(df['실제도착시간'])\n",
    "df['예상도착시간'] = pd.to_datetime(df['예상도착시간'])\n",
    "df1 = df.copy()\n",
    "df1 = df[df['예상도착시간'] < df['실제도착시간']]\n",
    "print(len(df1)) # (1) 정답: 510\n",
    "\n",
    "# (2) 이 중 거리가 7km 이상인 데이터의 수를 정수로 구하시오.\n",
    "df1_over = df1[df1['거리'] >= 7]\n",
    "print(int(len(df1_over))) # (2) 정답: 331\n",
    "\n",
    "# 만약 지연시간을 총 '분'으로 나타내는 파생변수 필요한 경우\n",
    "df1['지연시간'] = (df1['예상도착시간'] - df1['실제도착시간']).dt.total_seconds() / 60\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f01716",
   "metadata": {},
   "source": [
    "# 2유형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6340d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15326 entries, 0 to 15325\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             15326 non-null  int64  \n",
      " 1   city                    15326 non-null  object \n",
      " 2   city_development_index  15326 non-null  float64\n",
      " 3   gender                  11750 non-null  object \n",
      " 4   relevent_experience     15326 non-null  object \n",
      " 5   enrolled_university     15012 non-null  object \n",
      " 6   education_level         14961 non-null  object \n",
      " 7   major_discipline        13045 non-null  object \n",
      " 8   experience              15272 non-null  object \n",
      " 9   company_size            10539 non-null  object \n",
      " 10  company_type            10383 non-null  object \n",
      " 11  last_new_job            14984 non-null  object \n",
      " 12  training_hours          15326 non-null  int64  \n",
      " 13  target                  15326 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3832 entries, 0 to 3831\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             3832 non-null   int64  \n",
      " 1   city                    3832 non-null   object \n",
      " 2   city_development_index  3832 non-null   float64\n",
      " 3   gender                  2900 non-null   object \n",
      " 4   relevent_experience     3832 non-null   object \n",
      " 5   enrolled_university     3760 non-null   object \n",
      " 6   education_level         3737 non-null   object \n",
      " 7   major_discipline        3300 non-null   object \n",
      " 8   experience              3821 non-null   object \n",
      " 9   company_size            2681 non-null   object \n",
      " 10  company_type            2635 non-null   object \n",
      " 11  last_new_job            3751 non-null   object \n",
      " 12  training_hours          3832 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 389.3+ KB\n",
      "None\n",
      "(15326, 14) (3832, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3832 entries, 0 to 3831\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             3832 non-null   int64  \n",
      " 1   city                    3832 non-null   int64  \n",
      " 2   city_development_index  3832 non-null   float64\n",
      " 3   gender                  3832 non-null   int64  \n",
      " 4   relevent_experience     3832 non-null   int64  \n",
      " 5   enrolled_university     3832 non-null   int64  \n",
      " 6   education_level         3832 non-null   int64  \n",
      " 7   major_discipline        3832 non-null   int64  \n",
      " 8   experience              3832 non-null   int64  \n",
      " 9   company_size            3832 non-null   int64  \n",
      " 10  company_type            3832 non-null   int64  \n",
      " 11  last_new_job            3832 non-null   int64  \n",
      " 12  training_hours          3832 non-null   int64  \n",
      "dtypes: float64(1), int64(12)\n",
      "memory usage: 389.3 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15326 entries, 0 to 15325\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             15326 non-null  int64  \n",
      " 1   city                    15326 non-null  int64  \n",
      " 2   city_development_index  15326 non-null  float64\n",
      " 3   gender                  15326 non-null  int64  \n",
      " 4   relevent_experience     15326 non-null  int64  \n",
      " 5   enrolled_university     15326 non-null  int64  \n",
      " 6   education_level         15326 non-null  int64  \n",
      " 7   major_discipline        15326 non-null  int64  \n",
      " 8   experience              15326 non-null  int64  \n",
      " 9   company_size            15326 non-null  int64  \n",
      " 10  company_type            15326 non-null  int64  \n",
      " 11  last_new_job            15326 non-null  int64  \n",
      " 12  training_hours          15326 non-null  int64  \n",
      " 13  target                  15326 non-null  float64\n",
      "dtypes: float64(2), int64(12)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "(12260, 13) (3066, 13) (12260,) (3066,)\n",
      "0.6939147927705388 0.7893020221787345\n",
      "      pred\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      1.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "...    ...\n",
      "3827   0.0\n",
      "3828   0.0\n",
      "3829   0.0\n",
      "3830   0.0\n",
      "3831   0.0\n",
      "\n",
      "[3832 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 불러오기 및 확인\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_test.csv\")\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# 2. 결측값 처리 및 라벨 인코딩(object > 수치형)\n",
    " # 결측값 없음\n",
    " # 라벨 인코딩\n",
    "#  #1) get_dummies\n",
    "# # train과 test를 합쳐서 더미 처리하는 것이 중요 (같은 컬럼 유지 위함)\n",
    "# full = pd.concat([train, test], axis=0)\n",
    "\n",
    "# # get_dummies 적용 (object 타입 컬럼 자동 처리됨)\n",
    "# full_dummies = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# # 다시 train/test 분할\n",
    "# train_dummies = full_dummies[:len(train)]\n",
    "# test_dummies = full_dummies[len(train):]\n",
    "\n",
    " #2) LabelEncoding(한번에 하나의 컬럼만 가능함, 여러개 할 경우 나열하거나 for문 사용)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "columns = ['city', 'gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'experience', 'experience', 'company_size', 'company_type', 'last_new_job']\n",
    "for cols in columns:\n",
    "  encoder = LabelEncoder()\n",
    "  train[cols] = encoder.fit_transform(train[cols])\n",
    "  test[cols] = encoder.transform(test[cols])\n",
    "print(test.info())\n",
    "print(train.info())\n",
    "\n",
    "# 3. 데이터 분할\n",
    "features = train.drop('target', axis = 1)\n",
    "target = train['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 4. 모델 학습- 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier() #모델 객체 생성 \n",
    "model.fit(X_train, y_train)       #모델 학습 \n",
    "y_pred_val = model.predict(X_val) # val 데이터 예측\n",
    "\n",
    "# 5. 모델 평가\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "roc_auc = roc_auc_score(y_val, y_pred_val)\n",
    "acc_score = accuracy_score(y_val, y_pred_val)\n",
    "print(roc_auc, acc_score)\n",
    "\n",
    "# test 예측 및 결과 저장\n",
    "y_pred = model.predict(test)\n",
    "result = pd.DataFrame(y_pred, columns = ['pred'])\n",
    "result.to_csv('result.csv', index = False)\n",
    "\n",
    "result = pd.read_csv('result.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4c35e",
   "metadata": {},
   "source": [
    "# 회귀모델- 1. 항공권 가격 예측\n",
    "- 분류와 가장 큰 차이점은 평가지표가 다르다는 것\n",
    "- 분류에서 RandomForestClassifier를 사용한다면, 회귀에선 RandomForestRegressor를 사용한다.\n",
    "- 평가: RMSE\n",
    "- target: price\n",
    "- 최종 파일: result.csv(pred 컬럼 1개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfcf332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10505 entries, 0 to 10504\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           10505 non-null  object \n",
      " 1   flight            10505 non-null  object \n",
      " 2   source_city       10505 non-null  object \n",
      " 3   departure_time    10505 non-null  object \n",
      " 4   stops             10505 non-null  object \n",
      " 5   arrival_time      10505 non-null  object \n",
      " 6   destination_city  10505 non-null  object \n",
      " 7   class             10505 non-null  object \n",
      " 8   duration          10505 non-null  float64\n",
      " 9   days_left         10505 non-null  int64  \n",
      " 10  price             10505 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 902.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4502 entries, 0 to 4501\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           4502 non-null   object \n",
      " 1   flight            4502 non-null   object \n",
      " 2   source_city       4502 non-null   object \n",
      " 3   departure_time    4502 non-null   object \n",
      " 4   stops             4502 non-null   object \n",
      " 5   arrival_time      4502 non-null   object \n",
      " 6   destination_city  4502 non-null   object \n",
      " 7   class             4502 non-null   object \n",
      " 8   duration          4502 non-null   float64\n",
      " 9   days_left         4502 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 351.8+ KB\n",
      "None\n",
      "데이터 분할 이전:  (10505, 11) (4502, 10)\n",
      "count     10505.000000\n",
      "mean      20650.139838\n",
      "std       22570.924117\n",
      "min        1105.000000\n",
      "25%        4755.000000\n",
      "50%        7455.000000\n",
      "75%       42457.000000\n",
      "max      110936.000000\n",
      "Name: price, dtype: float64\n",
      "airline             0\n",
      "flight              0\n",
      "source_city         0\n",
      "departure_time      0\n",
      "stops               0\n",
      "arrival_time        0\n",
      "destination_city    0\n",
      "class               0\n",
      "duration            0\n",
      "days_left           0\n",
      "price               0\n",
      "dtype: int64\n",
      "airline             0\n",
      "flight              0\n",
      "source_city         0\n",
      "departure_time      0\n",
      "stops               0\n",
      "arrival_time        0\n",
      "destination_city    0\n",
      "class               0\n",
      "duration            0\n",
      "days_left           0\n",
      "dtype: int64\n",
      "airline에서 test에는 없는 항목값 set()\n",
      "flight에서 test에는 없는 항목값 {'6E-7292', '6E-6213', 'SG-6016', 'I5-678', 'G8-506', '6E-6616', '6E-825', 'AI-475', '6E-2169', 'SG-1074', 'G8-2231', 'G8-384', 'I5-764', '6E-6211', 'SG-3248', '6E-2168', 'I5-589', 'G8-681', '6E-2763', 'G8-237', '6E-2042', 'G8-203', 'SG-4031', '6E-177', '6E-6386', '6E-992', '6E-6479', '6E-5214', 'AI-627', 'G8-300', '6E-6085', 'I5-713', '6E-6084', 'AI-467', 'UK-671', 'SG-3229', '6E-244', '6E-318', '6E-149', '6E-5382', '6E-404', 'SG-2697', 'I5-735', 'AI-406', 'AI-745', 'AI-9857', '6E-6474', '6E-2053', 'SG-3719', '6E-2616', 'G8-209', 'SG-468', '6E-5384', '6E-6271', 'G8-191', '6E-171', '6E-2109', 'G8-347', 'G8-602', '6E-205', 'SG-1059', '6E-5026', '6E-6445', '6E-6098', '6E-176', '6E-929', 'G8-105', '6E-5218', 'AI-9843', '6E-544', 'AI-657', '6E-6717', '6E-7201', '6E-384', '6E-6086', '6E-455', '6E-6292'}\n",
      "source_city에서 test에는 없는 항목값 set()\n",
      "departure_time에서 test에는 없는 항목값 set()\n",
      "stops에서 test에는 없는 항목값 set()\n",
      "arrival_time에서 test에는 없는 항목값 set()\n",
      "destination_city에서 test에는 없는 항목값 set()\n",
      "class에서 test에는 없는 항목값 set()\n",
      "데이터 분할 이후:  (8404, 37) (2101, 37) (8404,) (2101,)\n",
      "4373.25\n",
      "          pred\n",
      "0     57821.13\n",
      "1      5382.65\n",
      "2     13361.39\n",
      "3      6010.25\n",
      "4      4890.24\n",
      "...        ...\n",
      "4497  13042.76\n",
      "4498   4666.94\n",
      "4499  23784.79\n",
      "4500  17504.35\n",
      "4501   2418.69\n",
      "\n",
      "[4502 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 불러오기 및 확인\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_test.csv\")\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "print(\"데이터 분할 이전: \",train.shape, test.shape)\n",
    "# **회귀분석은 target 변수 기술통계 확인\n",
    "print(train['price'].describe()) # mean 값이 median 값보다 크므로 오른쪽 긴 꼬리 왜곡임. 왼쪽 즉 가격 낮은것에 몰려있음.\n",
    "\n",
    "# 2. 결측치 처리 및 원핫인코딩\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# train['A'] = train['A'].fillna(train['A'].mean())\n",
    "# test['A'] = test['A'].fillna(test['A'].mean())\n",
    "\n",
    "# 원핫 인코딩\n",
    "\n",
    "# label encoder 전에 항목값 비교(만약 분류 예측이면 drop('범주형 target 변수명') 추가해야함)\n",
    "obj_cols = train.select_dtypes(include = 'object').columns\n",
    "for col in obj_cols:\n",
    "  diff = set(test[col]) - set(train[col]) \n",
    "  print(f\"{col}에서 test에는 없는 항목값 {diff}\")  # 'flight' 변수 상이함\n",
    "# *만약 항목이 상이한 train/test 변수가 있다면 삭제하는 방법 있음.* \n",
    "train = train.drop('flight', axis = 1)\n",
    "test = test.drop('flight', axis = 1)\n",
    "\n",
    "#*회귀모델에선 보통 원핫인코딩을 사용함\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# 3. 데이터 분할\n",
    "features = train.drop('price', axis = 1)\n",
    "target = train['price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size = 0.2, random_state = 42)\n",
    "print(\"데이터 분할 이후: \", X_train.shape, X_val.shape, y_train.shape, y_val.shape)  #************확인 필요!!!!***************\n",
    "\n",
    "# 4. 모델 학습 \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "# 5. 예측\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(test)\n",
    "\n",
    "# val 예측 평가 A\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "rmse = root_mean_squared_error(y_val,y_val_pred)\n",
    "print(round(rmse, 2))\n",
    "\n",
    "# 6. test 예측 결과 저장 \n",
    "result = pd.DataFrame(y_test_pred, columns = ['pred'])\n",
    "result.to_csv('result.csv', index = False)\n",
    "\n",
    "# 결과 확인\n",
    "result = pd.read_csv('result.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b0df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\my-project\\myenv\\lib\\site-packages (from statsmodels) (2.0.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\my-project\\myenv\\lib\\site-packages (from statsmodels) (1.15.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\my-project\\myenv\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\my-project\\myenv\\lib\\site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\my-project\\myenv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\my-project\\myenv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\my-project\\myenv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\my-project\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  9.7/9.8 MB 50.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 46.9 MB/s eta 0:00:00\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23aafe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===scipy.stats의 f_oneway() 사용===\n",
      "===\n",
      "정규성 검정===\n",
      "ShapiroResult(statistic=np.float64(0.9649054066073813), pvalue=np.float64(0.8400161543468654))\n",
      "ShapiroResult(statistic=np.float64(0.9468040874196029), pvalue=np.float64(0.6308700692815115))\n",
      "ShapiroResult(statistic=np.float64(0.9701646110856055), pvalue=np.float64(0.892367306190296))\n",
      "ShapiroResult(statistic=np.float64(0.9752339025839644), pvalue=np.float64(0.9346854448707653))\n",
      "\n",
      "===등분산성 검정===\n",
      "LeveneResult(statistic=np.float64(1.9355354288758708), pvalue=np.float64(0.14127835331346628))\n",
      "\n",
      "===일원 분산 분석===\n",
      "F_onewayResult(statistic=np.float64(89.12613851177174), pvalue=np.float64(1.0018381522523723e-16))\n",
      "\n",
      "===statsmodels의 ols() 사용=== \n",
      "=============\n",
      "            df    sum_sq    mean_sq          F        PR(>F)\n",
      "C(비료)      3.0  43.21875  14.406250  89.126139  1.001838e-16\n",
      "Residual  36.0   5.81900   0.161639        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# 문제: 4종류의 비료를 사용한 식물의 성장에 대한 실험 결과. 이 실험에서는 비슷한 조건의 식물 40개를 무작위로 10개씩 나누고 화학 비료 A, B, C, D를 일정 기간 사용한 후 성장량을 측정했다. 성장의 차이가 있는지 유의수준 0.05 하에서 검정하시오.\n",
    "\n",
    "# H0: 네가지 비료의 효과는 동일하다\n",
    "# H1: 비료의 효과에는 차이가 있다.(적어도 2가지 비료의 효과에는 차이가 있다.)\n",
    "\n",
    "print(\"===scipy.stats의 f_oneway() 사용===\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'A': [10.5, 11.3, 10.8, 9.6, 11.1, 10.2, 10.9, 11.4, 10.5, 10.3],\n",
    "    'B': [11.9, 12.4, 12.1, 13.2, 12.5, 11.8, 12.2, 12.9, 12.4, 12.3],\n",
    "    'C': [11.2, 11.7, 11.6, 10.9, 11.3, 11.1, 10.8, 11.5, 11.4, 11.0],\n",
    "    'D': [9.8, 9.4, 9.1, 9.5, 9.6, 9.9, 9.2, 9.7, 9.3, 9.4]\n",
    "})\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 정규성 검정\n",
    "print(\"===\\n정규성 검정===\")\n",
    "print(stats.shapiro(df['A']))\n",
    "print(stats.shapiro(df['B']))\n",
    "print(stats.shapiro(df['C']))\n",
    "print(stats.shapiro(df['D']))\n",
    "\n",
    "print(\"\\n===등분산성 검정===\")\n",
    "# 등분산성 검정\n",
    "print(stats.levene(df['A'], df['B'], df['C'], df['D']))\n",
    "\n",
    "print(\"\\n===일원 분산 분석===\")\n",
    "# 일원 분산 분석\n",
    "print(stats.f_oneway(df['A'], df['B'], df['C'], df['D']))\n",
    "\n",
    "print(\"\\n===statsmodels의 ols() 사용===\", \"\\n=============\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part3/ch2/fertilizer.csv\")\n",
    "\n",
    "from statsmodels.formula.api import ols # 회귀모델 만들기\n",
    "from statsmodels.stats.anova import anova_lm # 회귀모델로 분산분석표 출력\n",
    "model = ols('성장 ~ C(비료)', df).fit() #선형모델 학습\n",
    "print(anova_lm(model))\n",
    "# 결과정리\n",
    "## PR(>F) 가 0.05보다 작으면 그룹 간 차이가 있다고 봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6202",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "-5.529\n",
      "ShapiroResult(statistic=np.float64(0.43366370904065166), pvalue=np.float64(5.1593919864410894e-39)) ShapiroResult(statistic=np.float64(0.6361146555785815), pvalue=np.float64(2.580307332702185e-25))\n",
      "62175.0\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.info())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1번문제: 독립표본 t-검정\n",
    "fare_male = df[df['sex'] == 'male']['fare']\n",
    "fare_female = df[df['sex'] == 'female']['fare']\n",
    "\n",
    "#H0: 남녀 별 Fare의 평균은 같다.\n",
    "#H1: 남녀 별 Fare 평균은 다르다.\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_value = ttest_ind(fare_male, fare_female)\n",
    "print(round(t_stat, 3))\n",
    "\n",
    "# 정규성 검정\n",
    "from scipy.stats import shapiro\n",
    "result1 = shapiro(fare_male)\n",
    "result2 = shapiro(fare_female)\n",
    "print(result1, result2)\n",
    "\n",
    "# 만약 정규성 불만족이라면, 비모수 검정 만위트니 유 검정\n",
    "from scipy.stats import mannwhitneyu\n",
    "u_stat, p_val = mannwhitneyu(fare_male, fare_female) \n",
    "print(round(u_stat, 3))\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b9e551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BootstrapMethod',\n",
       " 'CensoredData',\n",
       " 'ConstantInputWarning',\n",
       " 'Covariance',\n",
       " 'DegenerateDataWarning',\n",
       " 'FitError',\n",
       " 'Mixture',\n",
       " 'MonteCarloMethod',\n",
       " 'NearConstantInputWarning',\n",
       " 'Normal',\n",
       " 'PermutationMethod',\n",
       " 'Uniform',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_ansari_swilk_statistics',\n",
       " '_axis_nan_policy',\n",
       " '_biasedurn',\n",
       " '_binned_statistic',\n",
       " '_binomtest',\n",
       " '_bws_test',\n",
       " '_censored_data',\n",
       " '_common',\n",
       " '_constants',\n",
       " '_continuous_distns',\n",
       " '_correlation',\n",
       " '_covariance',\n",
       " '_crosstab',\n",
       " '_discrete_distns',\n",
       " '_distn_infrastructure',\n",
       " '_distr_params',\n",
       " '_distribution_infrastructure',\n",
       " '_entropy',\n",
       " '_fit',\n",
       " '_hypotests',\n",
       " '_kde',\n",
       " '_ksstats',\n",
       " '_levy_stable',\n",
       " '_mannwhitneyu',\n",
       " '_mgc',\n",
       " '_morestats',\n",
       " '_mstats_basic',\n",
       " '_mstats_extras',\n",
       " '_multicomp',\n",
       " '_multivariate',\n",
       " '_mvn',\n",
       " '_new_distributions',\n",
       " '_odds_ratio',\n",
       " '_page_trend_test',\n",
       " '_probability_distribution',\n",
       " '_qmc',\n",
       " '_qmc_cy',\n",
       " '_qmvnt',\n",
       " '_rcont',\n",
       " '_relative_risk',\n",
       " '_resampling',\n",
       " '_sensitivity_analysis',\n",
       " '_sobol',\n",
       " '_stats',\n",
       " '_stats_mstats_common',\n",
       " '_stats_py',\n",
       " '_stats_pythran',\n",
       " '_survival',\n",
       " '_tukeylambda_stats',\n",
       " '_variation',\n",
       " '_warnings_errors',\n",
       " '_wilcoxon',\n",
       " 'abs',\n",
       " 'alexandergovern',\n",
       " 'alpha',\n",
       " 'anderson',\n",
       " 'anderson_ksamp',\n",
       " 'anglit',\n",
       " 'ansari',\n",
       " 'arcsine',\n",
       " 'argus',\n",
       " 'barnard_exact',\n",
       " 'bartlett',\n",
       " 'bayes_mvs',\n",
       " 'bernoulli',\n",
       " 'beta',\n",
       " 'betabinom',\n",
       " 'betanbinom',\n",
       " 'betaprime',\n",
       " 'biasedurn',\n",
       " 'binned_statistic',\n",
       " 'binned_statistic_2d',\n",
       " 'binned_statistic_dd',\n",
       " 'binom',\n",
       " 'binomtest',\n",
       " 'boltzmann',\n",
       " 'bootstrap',\n",
       " 'boschloo_exact',\n",
       " 'boxcox',\n",
       " 'boxcox_llf',\n",
       " 'boxcox_normmax',\n",
       " 'boxcox_normplot',\n",
       " 'bradford',\n",
       " 'brunnermunzel',\n",
       " 'burr',\n",
       " 'burr12',\n",
       " 'bws_test',\n",
       " 'cauchy',\n",
       " 'chatterjeexi',\n",
       " 'chi',\n",
       " 'chi2',\n",
       " 'chi2_contingency',\n",
       " 'chisquare',\n",
       " 'circmean',\n",
       " 'circstd',\n",
       " 'circvar',\n",
       " 'combine_pvalues',\n",
       " 'contingency',\n",
       " 'cosine',\n",
       " 'cramervonmises',\n",
       " 'cramervonmises_2samp',\n",
       " 'crystalball',\n",
       " 'cumfreq',\n",
       " 'describe',\n",
       " 'dgamma',\n",
       " 'differential_entropy',\n",
       " 'directional_stats',\n",
       " 'dirichlet',\n",
       " 'dirichlet_multinomial',\n",
       " 'distributions',\n",
       " 'dlaplace',\n",
       " 'dpareto_lognorm',\n",
       " 'dunnett',\n",
       " 'dweibull',\n",
       " 'ecdf',\n",
       " 'energy_distance',\n",
       " 'entropy',\n",
       " 'epps_singleton_2samp',\n",
       " 'erlang',\n",
       " 'exp',\n",
       " 'expectile',\n",
       " 'expon',\n",
       " 'exponnorm',\n",
       " 'exponpow',\n",
       " 'exponweib',\n",
       " 'f',\n",
       " 'f_oneway',\n",
       " 'false_discovery_control',\n",
       " 'fatiguelife',\n",
       " 'find_repeats',\n",
       " 'fisher_exact',\n",
       " 'fisk',\n",
       " 'fit',\n",
       " 'fligner',\n",
       " 'foldcauchy',\n",
       " 'foldnorm',\n",
       " 'friedmanchisquare',\n",
       " 'gamma',\n",
       " 'gausshyper',\n",
       " 'gaussian_kde',\n",
       " 'genexpon',\n",
       " 'genextreme',\n",
       " 'gengamma',\n",
       " 'genhalflogistic',\n",
       " 'genhyperbolic',\n",
       " 'geninvgauss',\n",
       " 'genlogistic',\n",
       " 'gennorm',\n",
       " 'genpareto',\n",
       " 'geom',\n",
       " 'gibrat',\n",
       " 'gmean',\n",
       " 'gompertz',\n",
       " 'goodness_of_fit',\n",
       " 'gstd',\n",
       " 'gumbel_l',\n",
       " 'gumbel_r',\n",
       " 'gzscore',\n",
       " 'halfcauchy',\n",
       " 'halfgennorm',\n",
       " 'halflogistic',\n",
       " 'halfnorm',\n",
       " 'hmean',\n",
       " 'hypergeom',\n",
       " 'hypsecant',\n",
       " 'invgamma',\n",
       " 'invgauss',\n",
       " 'invweibull',\n",
       " 'invwishart',\n",
       " 'iqr',\n",
       " 'irwinhall',\n",
       " 'jarque_bera',\n",
       " 'jf_skew_t',\n",
       " 'johnsonsb',\n",
       " 'johnsonsu',\n",
       " 'kappa3',\n",
       " 'kappa4',\n",
       " 'kde',\n",
       " 'kendalltau',\n",
       " 'kruskal',\n",
       " 'ks_1samp',\n",
       " 'ks_2samp',\n",
       " 'ksone',\n",
       " 'kstat',\n",
       " 'kstatvar',\n",
       " 'kstest',\n",
       " 'kstwo',\n",
       " 'kstwobign',\n",
       " 'kurtosis',\n",
       " 'kurtosistest',\n",
       " 'landau',\n",
       " 'laplace',\n",
       " 'laplace_asymmetric',\n",
       " 'levene',\n",
       " 'levy',\n",
       " 'levy_l',\n",
       " 'levy_stable',\n",
       " 'linregress',\n",
       " 'lmoment',\n",
       " 'log',\n",
       " 'loggamma',\n",
       " 'logistic',\n",
       " 'loglaplace',\n",
       " 'lognorm',\n",
       " 'logrank',\n",
       " 'logser',\n",
       " 'loguniform',\n",
       " 'lomax',\n",
       " 'make_distribution',\n",
       " 'mannwhitneyu',\n",
       " 'matrix_normal',\n",
       " 'maxwell',\n",
       " 'median_abs_deviation',\n",
       " 'median_test',\n",
       " 'mielke',\n",
       " 'mode',\n",
       " 'moment',\n",
       " 'monte_carlo_test',\n",
       " 'mood',\n",
       " 'morestats',\n",
       " 'moyal',\n",
       " 'mstats',\n",
       " 'mstats_basic',\n",
       " 'mstats_extras',\n",
       " 'multinomial',\n",
       " 'multiscale_graphcorr',\n",
       " 'multivariate_hypergeom',\n",
       " 'multivariate_normal',\n",
       " 'multivariate_t',\n",
       " 'mvn',\n",
       " 'mvsdist',\n",
       " 'nakagami',\n",
       " 'nbinom',\n",
       " 'ncf',\n",
       " 'nchypergeom_fisher',\n",
       " 'nchypergeom_wallenius',\n",
       " 'nct',\n",
       " 'ncx2',\n",
       " 'nhypergeom',\n",
       " 'norm',\n",
       " 'normal_inverse_gamma',\n",
       " 'normaltest',\n",
       " 'norminvgauss',\n",
       " 'obrientransform',\n",
       " 'order_statistic',\n",
       " 'ortho_group',\n",
       " 'page_trend_test',\n",
       " 'pareto',\n",
       " 'pearson3',\n",
       " 'pearsonr',\n",
       " 'percentileofscore',\n",
       " 'permutation_test',\n",
       " 'planck',\n",
       " 'pmean',\n",
       " 'pointbiserialr',\n",
       " 'poisson',\n",
       " 'poisson_binom',\n",
       " 'poisson_means_test',\n",
       " 'power',\n",
       " 'power_divergence',\n",
       " 'powerlaw',\n",
       " 'powerlognorm',\n",
       " 'powernorm',\n",
       " 'ppcc_max',\n",
       " 'ppcc_plot',\n",
       " 'probplot',\n",
       " 'qmc',\n",
       " 'quantile_test',\n",
       " 'randint',\n",
       " 'random_correlation',\n",
       " 'random_table',\n",
       " 'rankdata',\n",
       " 'ranksums',\n",
       " 'rayleigh',\n",
       " 'rdist',\n",
       " 'recipinvgauss',\n",
       " 'reciprocal',\n",
       " 'rel_breitwigner',\n",
       " 'relfreq',\n",
       " 'rice',\n",
       " 'rv_continuous',\n",
       " 'rv_discrete',\n",
       " 'rv_histogram',\n",
       " 'scoreatpercentile',\n",
       " 'sem',\n",
       " 'semicircular',\n",
       " 'shapiro',\n",
       " 'siegelslopes',\n",
       " 'sigmaclip',\n",
       " 'skellam',\n",
       " 'skew',\n",
       " 'skewcauchy',\n",
       " 'skewnorm',\n",
       " 'skewtest',\n",
       " 'sobol_indices',\n",
       " 'somersd',\n",
       " 'spearmanr',\n",
       " 'special_ortho_group',\n",
       " 'stats',\n",
       " 'studentized_range',\n",
       " 't',\n",
       " 'test',\n",
       " 'theilslopes',\n",
       " 'tiecorrect',\n",
       " 'tmax',\n",
       " 'tmean',\n",
       " 'tmin',\n",
       " 'trapezoid',\n",
       " 'trapz',\n",
       " 'triang',\n",
       " 'trim1',\n",
       " 'trim_mean',\n",
       " 'trimboth',\n",
       " 'truncate',\n",
       " 'truncexpon',\n",
       " 'truncnorm',\n",
       " 'truncpareto',\n",
       " 'truncweibull_min',\n",
       " 'tsem',\n",
       " 'tstd',\n",
       " 'ttest_1samp',\n",
       " 'ttest_ind',\n",
       " 'ttest_ind_from_stats',\n",
       " 'ttest_rel',\n",
       " 'tukey_hsd',\n",
       " 'tukeylambda',\n",
       " 'tvar',\n",
       " 'uniform',\n",
       " 'uniform_direction',\n",
       " 'unitary_group',\n",
       " 'variation',\n",
       " 'vonmises',\n",
       " 'vonmises_fisher',\n",
       " 'vonmises_line',\n",
       " 'wald',\n",
       " 'wasserstein_distance',\n",
       " 'wasserstein_distance_nd',\n",
       " 'weibull_max',\n",
       " 'weibull_min',\n",
       " 'weightedtau',\n",
       " 'wilcoxon',\n",
       " 'wishart',\n",
       " 'wrapcauchy',\n",
       " 'yeojohnson',\n",
       " 'yeojohnson_llf',\n",
       " 'yeojohnson_normmax',\n",
       " 'yeojohnson_normplot',\n",
       " 'yulesimon',\n",
       " 'zipf',\n",
       " 'zipfian',\n",
       " 'zmap',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1d9901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   항암약\n",
      "0    4\n",
      "1    4\n",
      "2    3\n",
      "3    4\n",
      "4    1\n",
      "0.55\n",
      "Power_divergenceResult(statistic=np.float64(6.976190476190476), pvalue=np.float64(0.07266054733847571))\n"
     ]
    }
   ],
   "source": [
    "# 3유형 -1 \n",
    "# 1. 감기약 위약을 투여받은 환자의 부작용은 항암약 위약을 투여받은 환자의 부작용과 차이가 있는가?\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"항암약\":[4,4,3,4,1,4,1,4,1,4,4,2,1,4,2,3,2,4,4,4]\n",
    "    })\n",
    "print(df.head())\n",
    "## H0: 감기약의 부작용과 항암약의 부작용은 동일하다.\n",
    "## H1: 감기약의 부작용과 항암약의 부작용은 다르다.\n",
    "\n",
    "# 항암약을 투여받은 환자 중 '이상없음'의 비율을 0과 1 사이로 구하시오.\n",
    "count = (df['항암약'] == 4).sum()\n",
    "count # 이상없음 11건\n",
    "\n",
    "ratio = count / len(df)\n",
    "print(ratio) # 0.55 \n",
    "# 또는 df['항암약'].value_counts(normalize = True) 를 통해 상대적 비율로 반환하여 답을 구할 수도 있다.\n",
    "\n",
    "# 2. 감기약의 예상 부작용 비율과 항암약의 부작용 관찰값이 통게적으로 유의미하게 차이가 있는지 확인. 카이제곱 검정을 사용해 검정통계량 구하시오.\n",
    "## 카이제곱 \n",
    "from scipy.stats import chisquare\n",
    "\n",
    "prob = [0.1, 0.05, 0.15, 0.7]\n",
    "\n",
    "# 기대빈도 계산\n",
    "expected_counts = [0.1*20, 0.05*20, 0.15*20, 0.7*20] # 기대비율로 제시된 경우 총 건수 곱해서 기대빈도수로 통일시켜줘야함.!\n",
    "# 관찰 빈도 계산\n",
    "observed_counts = [4, 3, 2, 11]\n",
    "\n",
    "# 카이제곱\n",
    "print(chisquare(f_obs = observed_counts, f_exp = expected_counts))\n",
    "# pvalue=np.float64(0.07266054733847573)로 0.05를 넘으므로 귀무가설 채택. 즉 서로 부작용이 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd9adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    solar  wind     o3  temperature\n",
      "0   89.14  6.28  33.52         23.0\n",
      "1  109.97  1.04  27.01         20.7\n",
      "2  102.83  6.42  41.00         20.5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            temperature   R-squared:                       0.044\n",
      "Model:                            OLS   Adj. R-squared:                  0.014\n",
      "Method:                 Least Squares   F-statistic:                     1.464\n",
      "Date:                Wed, 18 Jun 2025   Prob (F-statistic):              0.229\n",
      "Time:                        23:46:47   Log-Likelihood:                -195.45\n",
      "No. Observations:                 100   AIC:                             398.9\n",
      "Df Residuals:                      96   BIC:                             409.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     19.0507      1.994      9.555      0.000      15.093      23.008\n",
      "solar          0.0039      0.015      0.251      0.802      -0.027       0.035\n",
      "wind          -0.0252      0.090     -0.280      0.780      -0.204       0.153\n",
      "o3             0.0749      0.036      2.079      0.040       0.003       0.146\n",
      "==============================================================================\n",
      "Omnibus:                        0.654   Durbin-Watson:                   2.328\n",
      "Prob(Omnibus):                  0.721   Jarque-Bera (JB):                0.672\n",
      "Skew:                           0.187   Prob(JB):                        0.715\n",
      "Kurtosis:                       2.855   Cond. No.                     1.20e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.2e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "1번답:  0.07493854378136597\n",
      "2번답:  0.7797177202071699\n",
      "21.561630469479685\n"
     ]
    }
   ],
   "source": [
    "# 3유형 -2\n",
    "# 다중 선형회귀 모델을 구축하고, 각 소문제에 답하시오.\n",
    "## from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part4/ch6/data6-3-2.csv\")\n",
    "\n",
    "print(df.head(3))\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('temperature~solar+wind+o3', data = df).fit()\n",
    "print(model.summary()) \n",
    "print(\"1번답: \", model.params['o3'])\n",
    "# 답: 0.0749385437813658\n",
    "\n",
    "# 2. 문제 2-1에서 적합한 모델에서 solar와 o3이 고정된 상태에서 wind의 세기가 증가함에 따라 'temperature'가 감소한다. 이 회귀 모델에서 wind의 회귀계수에 대한 pvalue를 구하시오.\n",
    "print(\"2번답: \", model.pvalues['wind'])\n",
    "# 2번답:  0.7797177202071661\n",
    "\n",
    "# 3. 2-1에서 적합한 모델에서 solar:100, wind: 5, o3: 30일 때, 예측값을 구하시오.\n",
    "import pandas as pd\n",
    "new_data = pd.DataFrame({'solar': [100], 'wind':[5], 'o3':[30]})\n",
    "result = model.predict(new_data)\n",
    "print(result[0]) # 21.561630469479677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d36d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b82c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3cb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
